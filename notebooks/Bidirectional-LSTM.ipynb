{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "\n",
    "with open('../data/IMDB Dataset.csv') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',')\n",
    "    next(csv_reader, None)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        labels.append(row[1])\n",
    "        sentence = row[0]\n",
    "        \n",
    "        for word in stopwords:\n",
    "            token = \" \" + word + \" \"\n",
    "            sentence = sentence.replace(token, \" \").replace(\"  \", \" \")\n",
    "            \n",
    "        # Remove punctuations and numbers\n",
    "        sentence = re.sub(r'[^a-zA-Z]', ' ', sentence)\n",
    "        # Single character removal\n",
    "        sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "        # Removing multiple spaces\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        \n",
    "        sentences.append(sentence)\n",
    "\n",
    "sentences = preprocess_reviews(sentences)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match tag team table match bubba ray spike dudley vs eddie guerrero chris benoit bubba ray spike dudley started things off tag team table match eddie guerrero chris benoit according rules match opponents go tables order get win benoit guerrero heated early taking turns hammering first spike bubba ray german suplex benoit bubba took wind dudley brother spike tried help brother referee restrained benoit guerrero ganged corner with benoit stomping away bubba guerrero set table outside spike dashed ring somersaulted top rope onto guerrero outside after recovering taking care spike guerrero slipped table ring helped wolverine set up the tandem set double superplex middle rope put bubba table spike knocked table right brother came crashing down guerrero benoit propped another table corner tried irish whip spike it bubba dashed blocked brother bubba caught fire lifted opponents back body drops bubba slammed guerrero spike stomped wolverine off top rope bubba held benoit bay spike soar wassup headbutt shortly after benoit latched spike crossface match continued even spike tapped out bubba came brother rescue managed sprawl benoit table bubba leapt middle rope benoit moved sent bubba crashing wood but opponents didn force table bubba allowed stay match the first man eliminated shortly after though spike put eddie table dudley dawg ring apron outside benoit put spike table moments later even score within seconds bubba nailed bubba bomb put benoit table gave dudleys win winner bubba ray spike dudley br br match cruiserweight championship jamie noble vs billy kidman billy kidman challenged jamie noble brought nidia ring cruiserweight championship noble kidman locked tumbled ring raced back inside grappled more when kidman thwarted noble moves noble fled outside ring nidia gave encouragement the fight spread outside ring noble threw girlfriend challenger kidman tossed nidia aside taken modified arm bar noble continued attack kidman injured arm back ring kidman injured harm hampered offense continued battle hard noble tried put kidman away powerbomb challenger countered facebuster kidman went finish things shooting star press noble broke attempt kidman went shooting star press again time noble just rolled harm way noble flipped kidman power bomb soon got pin retain wwe cruiserweight championship winner jamie noble br br match european championship william regal vs jeff hardy william regal took jeff hardy next attempt win back european championship jeff catapulted regal top rope took hurracanrana off ring apron back ring jeff hit whisper wind knock regal loop jeff went swanton bomb regal got knees hit jeff devastating shot jeff managed surprise regal quick rollup though got pin keep european championship regal started bawling seeing hardy celebrate way back ramp winner jeff hardy br br match chris jericho vs john cena chris jericho promised end john cena career match vengeance came next jericho tried teach cena lesson match began suplexing mat jericho continued knock cena around ring cockiness got better him while top rope jericho began showboat allowed cena grab superplex cena followed tilt whirl slam taken nasty dropkick gut the rookie recovered hit belly belly suplex couldn put j away jericho launched lionsault cena dodged move jericho nailed bulldog connected lionsault not go cover he goaded cena feet put walls jericho cena ideas reversing move pin attempt getting jericho went berserk match winner john cena br br match intercontinental championship rvd vs brock lesnar via disqualification the next big thing mr pay per view tangled intercontinental championship line brock grabbed title ref draped shoulder momentarily glaring rvd van dam quickness gave brock fits early on the big man rolled ring kicked steel steps frustration brock pulled together began take charge with paul heyman beaming ringside brock slammed rvd hard floor outside ring from there brock began overpower rvd throwing ease top rope rvd landed painfully back suffer spine cracked steel ring steps the fight returned ring brock squeezing rvd around ribs rvd broke away soon leveled brock kick temple rvd followed rolling thunder brock managed kick two count the fight looked like might soon rvd went five star frog splash brock though hoisted van dam onto shoulder went rvd whirled brock ddt followed frog splash he went pin heyman pulled ref ring the ref immediately called disqualification soon traded blows heyman after rvd leapt onto brock top rope threatened hit van terminator heyman grabbed rvd leg brock picked champ time connected onto steel chair winner rvd br br match booker vs big show booker faced big show one on one next show withstood booker s kicks punches slapped booker corner after thrown ring booker picked chair ringside big show punched back booker face booker tried get back game choking show camera cable ringside booker smashed tv monitor spanish announcers position show skull delivered scissors kick put men table booker crawled back ring big show staggered moments later show grabbed booker throat met low blow kick face booker climbed top rope nailed somersaulting leg drop get pin winner booker br br announcement triple entered ring thunderous ovation fans hoped learn the game end competing before speak eric bishoff stopped the game apologize getting involved personal business if triple signed raw bischoff promised personal life never come play again bischoff said spent past two years networking hollywood he said everyone looking next breakout wwe superstar talking triple bischoff guaranteed triple signed raw getting top opportunities coming way stephanie mcmahon stepped issue pitch she said personal history triple two know well she said two unstoppable can again bischoff cut off begged stop stephanie cited triple told bischoff said triple no talent no charisma bischoff said young time didn know had still lot experience stephanie the two continued bicker back forth triple stepped microphone the game said easy say screw you either one them triple went shake bischoff hand pulled away he said rather go devil knows rather one doesn know before go further though shawn michaels came shake things up hbk said last thing wanted cause trouble he didn want get involved remembered pledging bring triple nwo hbk said nobody world triple better friends with hbk told friend imagine two back together again making bischoff life living hell triple said tempting offer he turned hugged hbk making official switch raw triple hbk left bischoff gloated victory bischoff said difference two got testicles doesn stephanie whacked bischoff side head left br br match tag team championship match christian lance storm vs hollywood hogan edge the match started loud usa chants hogan shoving christian ropes ring the canadians took there but edge scored kick christian head planted facebuster storm get tag hogan hogan began hulk soon caught christian big boot leg drop storm broke count christian tossed hogan ring storm superkicked icon edge tagged soon dropped opponents he speared corner turnbuckles missed spear strom hit ref hard instead edge nailed ddt ref not count test raced took hogan leveled edge boot storm tried get pin edge kicked two riksihi sprinted fend off test allowing edge recover spear storm christian distracted ref though j dashed clocked edge tag team championship storm rolled got pinfall win title winners new tag team champions christian lance storm br br match wwe undisputed championship triple threat match the rock vs kurt angle undertaker three wwe successful superstars lined triple threat match undisputed championship hanging balance taker the rock got face face kurt angle begging attention off side he got attention form beat form two men soon after taker spilled ring the rock brawled angle angle gave series suplexes took rock great one countered ddt managed two count the fight continued outside ring taker coming life clotheslining angle repeatedly smacking the rock taker rock got back ring taker dropped the rock sidewalk slam get two count rock rebounded grabbed taker throat chokeslammed him angle broke pin attempt likely given the rock title the rock retaliated latching ankle lock kurt angle angle reversed move rock bottomed people champion soon after the rock disposed angle hit people elbow undertaker angle tried take advantage disabling great one outside ring covering taker kicked two count outside ring rock took big swig nearby water bottle spewed liquid taker face blind champion taker didn stay disabled long managed overpower rock turn attention angle taker landed guillotine leg drop onto angle laying ring apron the rock picked just time break pin attempt kurt angle taker nailed rock ddt set chokeslam angle tried sneaking steel chair taker caught tomfoolery smacked hands the referee got caught ensuing fire didn see angle knock taker silly steel chair angle went cover taker the rock lay prone dead man somehow got shoulder up angle tried pin rock kicked out the rock got landed angle sharpshooter angle looked like tap taker kicked the rock submission hold taker picked rock crashed last ride while dead man covered win angle raced picked taker ankle lock taker went delirious pain managed counter he picked angle last ride angle put triangle choke it looked like taker pass out the rock broke angle hold find caught ankle lock rock got hold watched taker chokeslam angle rocky hit rock bottom taker refused go kicked out angle whirled taker angle slam rock bottomed great one pinned winner new wwe champion the rock br br finally decent ppv lately ppv weren good one winner give ppv br br \n"
     ]
    }
   ],
   "source": [
    "# Find max length in sentences\n",
    "longest_string = max(sentences, key=len)\n",
    "print(longest_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. Hyperparameters\n",
    "'''\n",
    "# vocab_size = 5000\n",
    "embedding_dim = 128\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.20, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "# tokenizer.fit_on_texts(X_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# Labels tokenizer - DO NOT DO THIS\n",
    "# labels_tokenizer = Tokenizer()\n",
    "# labels_tokenizer.fit_on_texts(labels)\n",
    "# # # Convert labels to integer encoding\n",
    "# y_train = labels_tokenizer.texts_to_sequences(y_train)\n",
    "# y_test = labels_tokenizer.texts_to_sequences(y_test)\n",
    "\n",
    "y_train = np.array(list(map(lambda x: 1 if x=='positive' else 0, y_train)))\n",
    "y_test = np.array(list(map(lambda x: 1 if x=='positive' else 0, y_test)))\n",
    "\n",
    "# Convert sequences to numpy array\n",
    "X_train, X_test = np.array(X_train), np.array(X_test)\n",
    "# y_train, y_test = np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51621"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: \n",
    "Difference between (i) tokenizing labels and converting it to sequences vs. (ii) simply converting it to 0s and 1s.\n",
    "\n",
    "- Model was getting weird result if (i), loss was decreasing to negatives but accuracy does not increase. \n",
    "\n",
    "Fit on text on train, test, or both?\n",
    "- You MUST use the same tokenizer in training and test data. It's not guaranteed that train and test data will have the same words with same frequencies, so each dataset will create a different dictionary when fit_on_texts is ran. The main idea of dividing your dataset into train and test is to evaluate your model for future unkown situations in a objetive way. That's said, if you fit your tokenizer on whole dataset you are somehow biasing your model. For a good evaluation of your model, you have to take in account the UNK tokens. So as any other kind of \"feature extraction\" the best practices are to ONLY FIT ON TRAIN and apply to all.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 100)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an LSTM model\n",
    "Sentiment analysis is a seq2vec problem. Keep this in mind when creating the input and output dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 128)          6607488   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                3096      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 6,709,425\n",
      "Trainable params: 6,709,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')    \n",
    "])\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.4208 - accuracy: 0.8005 - val_loss: 0.3378 - val_accuracy: 0.8536\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.2854 - accuracy: 0.8833 - val_loss: 0.3375 - val_accuracy: 0.8510\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 0.2424 - accuracy: 0.9018 - val_loss: 0.3897 - val_accuracy: 0.8511\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 0.1973 - accuracy: 0.9220 - val_loss: 0.4093 - val_accuracy: 0.8482\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 0.1492 - accuracy: 0.9424 - val_loss: 0.5083 - val_accuracy: 0.8360\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, validation_split=0.2, epochs=num_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.8444\n",
      "test loss, test acc: [0.4877476990222931, 0.8443999886512756]\n",
      "Generate predictions for all samples\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-634f5449965c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# print(predictions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for all samples\")\n",
    "predictions = model.predict(X_test)\n",
    "predictions = [1 if pred >= 0.5 else 0 for pred in predictions]\n",
    "# print(predictions)\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bi-lstm-50k-movie-reviews.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[4129  832]\n",
      " [ 724 4315]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      4961\n",
      "           1       0.84      0.86      0.85      5039\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "Test Accuracy score:  0.8444\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Metrics for 50000 IMDb reviews')\n",
    "# Confusion Matrix - Validation predict with gt y_test\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Classification Report\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "# Accuracy score\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8db5e500f51c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
